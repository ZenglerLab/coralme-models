{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.322457Z",
     "start_time": "2023-05-09T23:40:37.443625Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.339498Z",
     "start_time": "2023-05-09T23:40:38.323925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Math, Markdown\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.349090Z",
     "start_time": "2023-05-09T23:40:38.340539Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('/opt/developing/coralme.jdtibochab/coralme/io/JSONSCHEMA', 'r') as infile:\n",
    "#     schema = json.load(infile)\n",
    "# with open('/opt/developing/coralme.jdtibochab/coralme/io/JSONSCHEMA', 'w') as outfile:\n",
    "#     json.dump(schema, outfile, indent = 2, sort_keys = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.358820Z",
     "start_time": "2023-05-09T23:40:38.350554Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('automated-org-with-refs.xlsx', 'rb') as infile:\n",
    "#     source = pandas.read_excel(infile)\n",
    "\n",
    "# with open('automated-org-with-refs-tRNAs.xlsx', 'rb') as infile:\n",
    "#     target = pandas.read_excel(infile)\n",
    "\n",
    "# target.compare(source, align_axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.370402Z",
     "start_time": "2023-05-09T23:40:38.359717Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "element_re = re.compile(\"([A-Z][a-z]?)([0-9.]+[0-9.]?|(?=[A-Z])?)\")\n",
    "\n",
    "def elemental(string):\n",
    "    composition = {}\n",
    "    parsed = element_re.findall(string)\n",
    "    for (element, count) in parsed:\n",
    "        if count == \"\":\n",
    "            count = 1\n",
    "        else:\n",
    "            count = float(count)\n",
    "            int_count = int(count)\n",
    "            if count == int_count:\n",
    "                count = int_count\n",
    "            else:\n",
    "                warn(f\"{count} is not an integer (in formula {self.formula})\")\n",
    "        if element in composition:\n",
    "            composition[element] += count\n",
    "        else:\n",
    "            composition[element] = count\n",
    "    composition = { k:composition[k] for k in sorted(composition) if composition[k] != 0 }\n",
    "    return composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.381683Z",
     "start_time": "2023-05-09T23:40:38.371781Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    print(type(obj))\n",
    "    if isinstance(obj, (int, float)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, set):\n",
    "        return sorted(list(obj))\n",
    "    if isinstance(obj, list):\n",
    "        return sorted(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:38.395461Z",
     "start_time": "2023-05-09T23:40:38.382801Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('iJL1678b.json', 'r') as infile:\n",
    "#     data = infile.read()\n",
    "    \n",
    "# import json\n",
    "# with open('iJL1678b.json', 'r') as infile:\n",
    "#     old_json = json.load(infile)\n",
    "\n",
    "# # get dct to rename later\n",
    "# dct = {}\n",
    "# for idx, x in enumerate(old_json['metabolites']):\n",
    "#     if '_mod_' in old_json['metabolites'][idx]['id']:\n",
    "#         base = x['id'].split('_mod_')[0]\n",
    "#         cofs = x['id'].split('_mod_')[1:]\n",
    "#         for jdx, cof in enumerate(cofs):\n",
    "#             if ':' in cof:\n",
    "#                 cofs[jdx] = '{:s}({:s})'.format(cof.split(':')[1], cof.split(':')[0])\n",
    "#             else:\n",
    "#                 cofs[jdx] = '{:s}(1)'.format(cof)\n",
    "#         dct[old_json['metabolites'][idx]['id']] = '{:s}_mod_{:s}'.format(base, '_mod_'.join(cofs))\n",
    "\n",
    "# dct = { k:dct[k] for k in sorted(dct, key = len, reverse = True) }\n",
    "# # print(dct['EG50003-MONOMER_mod_pan4p_mod_thex2e'])\n",
    "    \n",
    "# for k,v in tqdm(dct.items()):\n",
    "#     data = data.replace(k, v)\n",
    "\n",
    "# import pandas\n",
    "# with open('ecolime-fluxes-from-model.txt', 'r') as infile:\n",
    "#     old = pandas.read_csv(infile, sep = '\\t', header = None, index_col = 0).index\n",
    "# with open('ecolime-new-reaction-names.txt', 'r') as infile:\n",
    "#     new = pandas.read_csv(infile, sep = '\\t', header = None, index_col = 0).index\n",
    "    \n",
    "# dct = { k:v for k,v in zip(old, new) }\n",
    "# dct = { k:dct[k] for k in sorted(dct, key = len, reverse = True) }\n",
    "# len(dct)\n",
    "\n",
    "# for k,v in tqdm(dct.items()):\n",
    "#     data = data.replace(k, v)\n",
    "\n",
    "# # final replace\n",
    "# while '(1)(1)' in data:\n",
    "#     data = data.replace('(1)(1)', '(1)')\n",
    "# while '(1)(6)' in data:\n",
    "#     data = data.replace('(1)(6)', '(6)')\n",
    "# while 'lipoyl_scavenging(1)' in data:\n",
    "#     data = data.replace('lipoyl_scavenging(1)', 'lipoyl_scavenging')\n",
    "# while 'lipoyl_scavenging(1)' in data:\n",
    "#     data = data.replace('lipoyl_denovo(1)', 'lipoyl_denovo')\n",
    "\n",
    "# with open('iJL1678b-new-IDs.json', 'w') as outfile:\n",
    "#     outfile.write(data)\n",
    "\n",
    "# # sort JSON after renaming IDs\n",
    "# import json\n",
    "# with open('iJL1678b-new-IDs.json', 'r') as infile:\n",
    "#     old_json = json.load(infile)\n",
    "    \n",
    "# # left_pos and right_pos are now lists\n",
    "# for idx, x in enumerate(old_json['metabolites']):\n",
    "#     if list(old_json['metabolites'][idx]['metabolite_type'].keys())[0] == 'TranscribedGene':\n",
    "#         right_pos = old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['right_pos']\n",
    "#         if right_pos is None:\n",
    "#             old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['right_pos'] = None\n",
    "#         else:\n",
    "#             old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['right_pos'] = [str(right_pos)]\n",
    "            \n",
    "#         left_pos = old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['left_pos']\n",
    "#         if left_pos is None:\n",
    "#             old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['left_pos'] = None\n",
    "#         else:\n",
    "#             old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['left_pos'] = [str(left_pos)]\n",
    "\n",
    "# # remove 'variable_kind'\n",
    "# for idx, x in enumerate(old_json['reactions']):\n",
    "#     old_json['reactions'][idx].pop('variable_kind')\n",
    "\n",
    "# dct = {\n",
    "#     'CPLX0-782_mod_4fe4s_regeneration' : 'CPLX0-782_mod_4fe4s(2)_regeneration',\n",
    "#     '2OXOGLUTARATEDEH-CPLX_mod_mg2(1)_mod_lipoyl(1)' : '2OXOGLUTARATEDEH-CPLX_mod_mg2(1)_mod_lipoyl(1)_lipoyl_denovo_corrected',\n",
    "#     '2OXOGLUTARATEDEH-CPLX_mod_mg2(1)_mod_lipoyl(1)alt' : '2OXOGLUTARATEDEH-CPLX_mod_mg2(1)_mod_lipoyl(1)_lipoyl_scavenging',\n",
    "#     'GCVMULTI-CPLX_mod_lipoyl(1)' : 'GCVMULTI-CPLX_mod_lipoyl(1)_lipoyl_denovo_corrected',\n",
    "#     'GCVMULTI-CPLX_mod_lipoyl(1)alt' : 'GCVMULTI-CPLX_mod_lipoyl(1)_lipoyl_scavenging',\n",
    "#     'Fe_transfer_CyaY_mod_1:fe2_to_IscU' : 'Fe_transfer_CyaY_mod_fe2(1)_to_IscU',\n",
    "#     'Fe_transfer_CyaY_mod_1:fe2_to_IscU_mod_1:2Fe2S' : 'Fe_transfer_CyaY_mod_fe2(1)_to_IscU_mod_2Fe2S(1)',\n",
    "#     'Fe_transfer_CyaY_mod_1:fe2_to_IscU_mod_1:2Fe2S_mod_1:fe2' : 'Fe_transfer_CyaY_mod_fe2(1)_to_IscU_mod_2Fe2S(1)_mod_fe2(1)',\n",
    "#     'Fe_transfer_CyaY_mod_1:fe2_to_IscU_mod_1:fe2' : 'Fe_transfer_CyaY_mod_fe2(1)_to_IscU_mod_fe2(1)',\n",
    "#     'S_transfer_to_IscU_mod_1:2Fe1S' : 'S_transfer_to_IscU_mod_2Fe1S(1)',\n",
    "#     'S_transfer_to_IscU_mod_1:2Fe2S_mod_1:2Fe1S' : 'S_transfer_to_IscU_mod_2Fe2S(1)_mod_2Fe1S(1)',\n",
    "#     'S_transfer_to_IscU_mod_1:2Fe2S_mod_2:fe2' : 'S_transfer_to_IscU_mod_2Fe2S(1)_mod_fe2(2)',\n",
    "#     'S_transfer_to_IscU_mod_2:fe2' : 'S_transfer_to_IscU_mod_fe2(2)',\n",
    "#     'S_transfer_to_SufBCD_mod_1:2Fe1S' : 'S_transfer_to_SufBCD_mod_2Fe1S(1)',\n",
    "#     'S_transfer_to_SufBCD_mod_1:2Fe2S_mod_1:2Fe1S' : 'S_transfer_to_SufBCD_mod_2Fe2S(1)_mod_2Fe1S(1)',\n",
    "#     'S_transfer_to_SufBCD_mod_1:2Fe2S(1)_mod_2:fe2' : 'S_transfer_to_SufBCD_mod_2Fe2S(1)_mod_fe2(2)',\n",
    "#     'S_transfer_to_SufBCD_mod_2:fe2' : 'S_transfer_to_SufBCD_mod_fe2(2)',\n",
    "#     'SufBCD_mod_1:2Fe2S_atp_mediated_FE_loading' : 'SufBCD_mod_2Fe2S(1)_atp_mediated_FE_loading',\n",
    "#     'SufBCD_mod_1:2Fe2S_mod_1:fe2_atp_mediated_FE_loading' : 'SufBCD_mod_2Fe2S(1)_mod_fe2(1)_atp_mediated_FE_loading',\n",
    "#     'SufBCD_mod_1:fe2_atp_mediated_FE_loading' : 'SufBCD_mod_fe2(1)_atp_mediated_FE_loading',\n",
    "# }\n",
    "    \n",
    "# # rename specific \"id\"\n",
    "# for idx, x in enumerate(old_json['process_data']):\n",
    "#     if old_json['process_data'][idx]['id'] in list(dct.keys()):\n",
    "#         old_json['process_data'][idx]['id'] = dct[old_json['process_data'][idx]['id']]\n",
    "                   \n",
    "# # sort\n",
    "# old_json['reactions'] = sorted(old_json['reactions'], key = lambda x: (list(x['reaction_type'].keys())[0], x['id']))\n",
    "# old_json['metabolites'] = sorted(old_json['metabolites'], key = lambda x: (list(x['metabolite_type'].keys())[0], x['id']))\n",
    "# old_json['process_data'] = sorted(old_json['process_data'], key = lambda x: (list(x['process_data_type'].keys())[0], x['id']))\n",
    "    \n",
    "# for idx, x in enumerate(old_json['metabolites']):\n",
    "#     if old_json['metabolites'][idx]['formula'] is not None:\n",
    "#         old_json['metabolites'][idx]['formula'] = elemental(old_json['metabolites'][idx]['formula'])\n",
    "#     if list(old_json['metabolites'][idx]['metabolite_type'].keys())[0] == 'Complex':\n",
    "#         del old_json['metabolites'][idx]['compartment']\n",
    "#         del old_json['metabolites'][idx]['name']\n",
    "#     if list(old_json['metabolites'][idx]['metabolite_type'].keys())[0] == 'TranscribedGene':\n",
    "#         del old_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['nucleotide_sequence']\n",
    "\n",
    "# # remove metadata\n",
    "# for idx, x in enumerate(old_json['process_data']):\n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranslationData':\n",
    "#         del old_json['process_data'][idx]['process_data_type']['TranslationData']['nucleotide_sequence']\n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranscriptionData':\n",
    "#         del old_json['process_data'][idx]['process_data_type']['TranscriptionData']['nucleotide_sequence']\n",
    "\n",
    "# # sort\n",
    "# for idx, x in enumerate(old_json['reactions']):\n",
    "#     if list(old_json['reactions'][idx]['reaction_type'].keys())[0] == 'MetabolicReaction':        \n",
    "#         tmp = old_json['reactions'][idx]['reaction_type']['MetabolicReaction']['keff']\n",
    "#         old_json['reactions'][idx]['reaction_type']['MetabolicReaction']['keff'] = float(tmp)\n",
    "\n",
    "# for idx, x in enumerate(old_json['process_data']):\n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'ComplexData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['ComplexData']['subreactions']\n",
    "#         old_json['process_data'][idx]['process_data_type']['ComplexData']['subreactions'] = { k:float(tmp[k]) for k in sorted(tmp) }\n",
    "            \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranslationData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['TranslationData']['subreactions']\n",
    "#         old_json['process_data'][idx]['process_data_type']['TranslationData']['subreactions'] = { k:tmp[k] for k in sorted(tmp) }\n",
    "\n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranscriptionData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['TranscriptionData']['RNA_products']\n",
    "#         old_json['process_data'][idx]['process_data_type']['TranscriptionData']['RNA_products'] = sorted(tmp)\n",
    "        \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'GenericData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['GenericData']['component_list']\n",
    "#         old_json['process_data'][idx]['process_data_type']['GenericData']['component_list'] = sorted(tmp)\n",
    "            \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'PostTranslationData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['PostTranslationData']['translocation']\n",
    "#         old_json['process_data'][idx]['process_data_type']['PostTranslationData']['translocation'] = sorted(tmp)\n",
    "            \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'StoichiometricData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['StoichiometricData']['_stoichiometry']\n",
    "#         old_json['process_data'][idx]['process_data_type']['StoichiometricData']['_stoichiometry'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 } \n",
    "        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['StoichiometricData']['subreactions']\n",
    "#         old_json['process_data'][idx]['process_data_type']['StoichiometricData']['subreactions'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }  \n",
    "        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['StoichiometricData']['lower_bound']\n",
    "#         old_json['process_data'][idx]['process_data_type']['StoichiometricData']['lower_bound'] = float(tmp)\n",
    "        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['StoichiometricData']['upper_bound']\n",
    "#         old_json['process_data'][idx]['process_data_type']['StoichiometricData']['upper_bound'] = float(tmp)\n",
    "            \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['SubreactionData']['element_contribution']\n",
    "#         old_json['process_data'][idx]['process_data_type']['SubreactionData']['element_contribution'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }\n",
    "            \n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['SubreactionData']['stoichiometry']\n",
    "#         old_json['process_data'][idx]['process_data_type']['SubreactionData']['stoichiometry'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }\n",
    "\n",
    "#     if list(old_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "#         tmp = old_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme']\n",
    "#         if isinstance(tmp, list):\n",
    "#             old_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme'] = sorted(tmp)\n",
    "#         else:\n",
    "#             old_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme'] = [tmp]\n",
    "            \n",
    "# import json\n",
    "# with open('iJL1678b-new-IDs-sorted.json', 'w') as outfile:\n",
    "#     json.dump(old_json, outfile, indent = 2, sort_keys = True, default = set_default)\n",
    "    \n",
    "# # with open('iJL1678b-new-IDs-sorted.json', 'r') as infile:\n",
    "# #     data = infile.read()\n",
    "\n",
    "# # data = data.replace('_Outer_Membrane', '')\n",
    "# # data = data.replace('_Inner_Membrane', '')\n",
    "# # data = data.replace('_Membrane', '')\n",
    "# # data = data.replace('_Periplasm', '')\n",
    "\n",
    "# # with open('iJL1678b-new-IDs-sorted.json', 'w') as outfile:\n",
    "# #     outfile.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:40.703170Z",
     "start_time": "2023-05-09T23:40:38.396679Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# needed to remove keys from global_info not in original cobrame/ecolime\n",
    "with open('iJL1678b-new-IDs-sorted.json', 'r') as infile:\n",
    "    old_json = json.load(infile)\n",
    "    \n",
    "old_json['metabolites'] = [ x for x in old_json['metabolites'] \n",
    "                           if x['id'] not in ['RNase_m5', 'RNase_m16', 'RNase_m23', 'cs_p', 'cs_e', 'pqq_e'] ]\n",
    "old_json['reactions'] = [ x for x in old_json['reactions'] if x['upper_bound'] != 0 ]\n",
    "\n",
    "with open('iJL1678b-new-IDs-sorted.json', 'w') as outfile:\n",
    "    json.dump(old_json, outfile, indent = 2, sort_keys = True, default = set_default)\n",
    "\n",
    "for file in ['MEModel-step2-iJL1678b-ME']:\n",
    "    with open(file + '.json', 'r') as infile:\n",
    "        new_json = json.load(infile)\n",
    "\n",
    "    # sort\n",
    "    new_json['reactions'] = sorted(new_json['reactions'], key = lambda x: (list(x['reaction_type'].keys())[0], x['id']))\n",
    "    new_json['metabolites'] = sorted(new_json['metabolites'], key = lambda x: (list(x['metabolite_type'].keys())[0], x['id']))\n",
    "    new_json['process_data'] = sorted(new_json['process_data'], key = lambda x: (list(x['process_data_type'].keys())[0], x['id']))\n",
    "\n",
    "    # remove keys from global_info not in original cobrame/ecolime\n",
    "    new_json['global_info'] = { k:v for k,v in new_json['global_info'].items() if k in list(old_json['global_info'].keys()) }\n",
    "    \n",
    "    for idx, x in enumerate(new_json['metabolites']):\n",
    "        if new_json['metabolites'][idx]['formula'] is not None:\n",
    "            new_json['metabolites'][idx]['formula'] = elemental(new_json['metabolites'][idx]['formula'])\n",
    "        if list(new_json['metabolites'][idx]['metabolite_type'].keys())[0] == 'Complex':\n",
    "            del new_json['metabolites'][idx]['compartment']\n",
    "            del new_json['metabolites'][idx]['name']\n",
    "        if list(new_json['metabolites'][idx]['metabolite_type'].keys())[0] == 'TranscribedGene':\n",
    "            del new_json['metabolites'][idx]['metabolite_type']['TranscribedGene']['nucleotide_sequence']\n",
    "\n",
    "    # ecolime doesn't have transl_table or translation in TranslationData\n",
    "    for idx, x in enumerate(new_json['process_data']):\n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranslationData':\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranslationData']['translation']\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranslationData']['transl_table']\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranslationData']['organelle']\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranslationData']['nucleotide_sequence']\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranscriptionData':\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranscriptionData']['organelle']\n",
    "            del new_json['process_data'][idx]['process_data_type']['TranscriptionData']['nucleotide_sequence']\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'PostTranslationReaction':\n",
    "            new_json['process_data'][idx]['process_data_type']['id'] = '_'.join(new_json['process_data'][idx]['process_data_type']['id'].split('_'))[:2]\n",
    "\n",
    "    # sort\n",
    "    for idx, x in enumerate(new_json['process_data']):\n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'ComplexData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['ComplexData']['subreactions']\n",
    "            new_json['process_data'][idx]['process_data_type']['ComplexData']['subreactions'] = { k:float(tmp[k]) for k in sorted(tmp) }\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranslationData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['TranslationData']['subreactions']\n",
    "            new_json['process_data'][idx]['process_data_type']['TranslationData']['subreactions'] = { k:tmp[k] for k in sorted(tmp) }\n",
    "\n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'TranscriptionData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['TranscriptionData']['RNA_products']\n",
    "            new_json['process_data'][idx]['process_data_type']['TranscriptionData']['RNA_products'] = sorted(tmp)\n",
    "\n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'GenericData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['GenericData']['component_list']\n",
    "            new_json['process_data'][idx]['process_data_type']['GenericData']['component_list'] = sorted(tmp)\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'PostTranslationData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['PostTranslationData']['translocation']\n",
    "            new_json['process_data'][idx]['process_data_type']['PostTranslationData']['translocation'] = sorted(tmp)\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'StoichiometricData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['StoichiometricData']['_stoichiometry']\n",
    "            new_json['process_data'][idx]['process_data_type']['StoichiometricData']['_stoichiometry'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 } \n",
    "        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['StoichiometricData']['subreactions']\n",
    "            new_json['process_data'][idx]['process_data_type']['StoichiometricData']['subreactions'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }\n",
    "            \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['StoichiometricData']['lower_bound']\n",
    "            new_json['process_data'][idx]['process_data_type']['StoichiometricData']['lower_bound'] = float(tmp)\n",
    "\n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['StoichiometricData']['upper_bound']\n",
    "            new_json['process_data'][idx]['process_data_type']['StoichiometricData']['upper_bound'] = float(tmp)\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['SubreactionData']['element_contribution']\n",
    "            new_json['process_data'][idx]['process_data_type']['SubreactionData']['element_contribution'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }\n",
    "            \n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['SubreactionData']['stoichiometry']\n",
    "            new_json['process_data'][idx]['process_data_type']['SubreactionData']['stoichiometry'] = { k:float(tmp[k]) for k in sorted(tmp) if float(tmp[k]) != 0 }\n",
    "\n",
    "        if list(new_json['process_data'][idx]['process_data_type'].keys())[0] == 'SubreactionData':        \n",
    "            tmp = new_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme']\n",
    "            if isinstance(tmp, list):\n",
    "                new_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme'] = sorted(tmp)\n",
    "            else:\n",
    "                new_json['process_data'][idx]['process_data_type']['SubreactionData']['enzyme'] = [tmp]\n",
    "    \n",
    "    # remove inactive reactions\n",
    "    new_json['reactions'] = [ x for x in new_json['reactions'] if x['upper_bound'] != 0 ]\n",
    "            \n",
    "    import json\n",
    "    with open(file + '-sorted.json', 'w') as outfile:\n",
    "        json.dump(new_json, outfile, indent = 2, sort_keys = True, default = set_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-09T23:40:40.715230Z",
     "start_time": "2023-05-09T23:40:40.704734Z"
    }
   },
   "outputs": [],
   "source": [
    "# _mod_lipoyl(1)alt -> _mod_lipoyl(1)_lipoyl_scavenging\n",
    "# _mod_lipoyl(1) -> _mod_lipoyl(1)_lipoyl_denovo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV :: py3.10 :: COBRAME-DEV",
   "language": "python",
   "name": "venv-p310-cobrame-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
